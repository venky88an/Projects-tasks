{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.5.0 in c:\\programdata\\anaconda3\\envs\\pyto\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\envs\\pyto\\lib\\site-packages (from torch==1.5.0) (0.18.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\pyto\\lib\\site-packages (from torch==1.5.0) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torchvision==0.4.2+cpu\n",
      "  Using cached https://download.pytorch.org/whl/cpu/torchvision-0.4.2%2Bcpu-cp36-cp36m-win_amd64.whl (751 kB)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\pyto\\lib\\site-packages (from torchvision==0.4.2+cpu) (1.14.0)\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\envs\\pyto\\lib\\site-packages (from torchvision==0.4.2+cpu) (1.5.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\pyto\\lib\\site-packages (from torchvision==0.4.2+cpu) (1.18.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\programdata\\anaconda3\\envs\\pyto\\lib\\site-packages (from torchvision==0.4.2+cpu) (7.1.2)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\envs\\pyto\\lib\\site-packages (from torch->torchvision==0.4.2+cpu) (0.18.2)\n",
      "Installing collected packages: torchvision\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.1.8\n",
      "    Uninstalling torchvision-0.1.8:\n",
      "      Successfully uninstalled torchvision-0.1.8\n",
      "Successfully installed torchvision-0.4.2+cpu\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision==0.4.2+cpu -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5963, 0.1926, 0.6496], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x=torch.rand(3, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "w=torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output=(w*3).sum()\n",
    "    model_output.backward()\n",
    "    print(model_output)\n",
    "    print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 4, #features: 1\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "print(f'#samples: {n_samples}, #features: {n_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "X_test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 0) Prepare data\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numpy; X_numpy.dtype # to have the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3474603 ],\n",
       "       [ 0.3523434 ],\n",
       "       [ 0.9546986 ],\n",
       "       [ 0.03592805],\n",
       "       [ 0.04800625],\n",
       "       [ 0.04860301],\n",
       "       [ 0.72334161],\n",
       "       [ 0.80208661],\n",
       "       [-1.14379857],\n",
       "       [ 0.17941071],\n",
       "       [-0.64770677],\n",
       "       [-1.11281215],\n",
       "       [-1.58457724],\n",
       "       [-0.08798693],\n",
       "       [ 2.47658416],\n",
       "       [-0.7322647 ],\n",
       "       [ 1.54697933],\n",
       "       [-0.13070464],\n",
       "       [ 0.30044554],\n",
       "       [-0.9443686 ],\n",
       "       [-0.30296397],\n",
       "       [-0.37444492],\n",
       "       [-1.15681626],\n",
       "       [ 0.59857517],\n",
       "       [-2.37977527],\n",
       "       [-0.60768369],\n",
       "       [ 0.54245131],\n",
       "       [ 2.02240507],\n",
       "       [ 0.04613557],\n",
       "       [ 0.52324766],\n",
       "       [ 0.29714121],\n",
       "       [-1.54292905],\n",
       "       [ 1.69235772],\n",
       "       [ 0.20931349],\n",
       "       [-0.41830152],\n",
       "       [ 0.87084178],\n",
       "       [-1.14747663],\n",
       "       [-0.17521053],\n",
       "       [-0.9617768 ],\n",
       "       [ 0.1886462 ],\n",
       "       [ 1.20200259],\n",
       "       [ 1.99008302],\n",
       "       [-1.36096559],\n",
       "       [-0.05455871],\n",
       "       [ 1.16418756],\n",
       "       [-1.45553433],\n",
       "       [ 0.01908996],\n",
       "       [-0.77873992],\n",
       "       [ 0.03754749],\n",
       "       [-0.34610187],\n",
       "       [-0.65122583],\n",
       "       [ 0.15846954],\n",
       "       [-1.20894816],\n",
       "       [-0.64764453],\n",
       "       [ 0.91484096],\n",
       "       [-1.84087587],\n",
       "       [ 0.49995133],\n",
       "       [ 1.27181862],\n",
       "       [ 0.69359851],\n",
       "       [ 0.55618522],\n",
       "       [ 0.4250724 ],\n",
       "       [-1.09712188],\n",
       "       [-0.5648753 ],\n",
       "       [ 0.35099715],\n",
       "       [ 0.83783635],\n",
       "       [ 0.05443274],\n",
       "       [-0.0093601 ],\n",
       "       [-2.35807363],\n",
       "       [-0.98299165],\n",
       "       [ 0.93465006],\n",
       "       [ 0.79523395],\n",
       "       [ 0.50991978],\n",
       "       [-0.17146461],\n",
       "       [ 0.15989294],\n",
       "       [ 2.22336022],\n",
       "       [ 0.33225315],\n",
       "       [ 0.05056171],\n",
       "       [-0.52819607],\n",
       "       [ 0.43027133],\n",
       "       [ 1.63574754],\n",
       "       [ 0.78660228],\n",
       "       [-0.60688728],\n",
       "       [ 0.39429521],\n",
       "       [ 0.7965119 ],\n",
       "       [-1.07529009],\n",
       "       [-0.19674528],\n",
       "       [ 0.8365287 ],\n",
       "       [-0.49581852],\n",
       "       [ 1.3799201 ],\n",
       "       [ 0.067471  ],\n",
       "       [-0.99590893],\n",
       "       [-0.90543814],\n",
       "       [-0.27620335],\n",
       "       [ 0.24266016],\n",
       "       [ 0.50977885],\n",
       "       [ 0.33225003],\n",
       "       [-1.10558404],\n",
       "       [ 2.08787087],\n",
       "       [ 0.28086468],\n",
       "       [ 0.61866969]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format changing based on the need in terms of tensor\n",
    "y = y.view(y.shape[0], 1)\n",
    "y.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-126.2492],\n",
       "        [  50.9288],\n",
       "        [  63.1546],\n",
       "        [   6.0547],\n",
       "        [  -5.7295],\n",
       "        [  -2.7519],\n",
       "        [  58.7036],\n",
       "        [  53.8136],\n",
       "        [ -95.3411],\n",
       "        [  24.6481],\n",
       "        [ -59.4170],\n",
       "        [ -73.4235],\n",
       "        [-104.1627],\n",
       "        [  31.8077],\n",
       "        [ 171.1535],\n",
       "        [ -67.7520],\n",
       "        [ 141.4677],\n",
       "        [ -24.3676],\n",
       "        [  -2.1124],\n",
       "        [ -32.5958],\n",
       "        [ -29.4151],\n",
       "        [ -37.8715],\n",
       "        [-101.8983],\n",
       "        [  46.4129],\n",
       "        [-181.3484],\n",
       "        [ -31.7740],\n",
       "        [  24.1315],\n",
       "        [ 163.9438],\n",
       "        [  10.7737],\n",
       "        [  37.3589],\n",
       "        [   0.9804],\n",
       "        [-120.8857],\n",
       "        [ 138.1994],\n",
       "        [   9.2027],\n",
       "        [ -16.2069],\n",
       "        [  33.2171],\n",
       "        [ -45.6170],\n",
       "        [  -1.7776],\n",
       "        [-105.5628],\n",
       "        [   5.2639],\n",
       "        [  89.5979],\n",
       "        [ 146.1030],\n",
       "        [ -77.7870],\n",
       "        [  -3.8089],\n",
       "        [  60.8120],\n",
       "        [ -97.2027],\n",
       "        [  -1.1599],\n",
       "        [ -43.8825],\n",
       "        [  15.7428],\n",
       "        [ -24.2745],\n",
       "        [ -90.6015],\n",
       "        [ -19.0731],\n",
       "        [-101.7900],\n",
       "        [ -56.5514],\n",
       "        [  52.1697],\n",
       "        [-158.2847],\n",
       "        [  64.5397],\n",
       "        [  84.5210],\n",
       "        [  66.4343],\n",
       "        [  36.8660],\n",
       "        [  37.4378],\n",
       "        [ -82.9171],\n",
       "        [ -21.4183],\n",
       "        [  -5.5435],\n",
       "        [  59.8845],\n",
       "        [   8.3785],\n",
       "        [ -17.1763],\n",
       "        [-160.5090],\n",
       "        [-100.7372],\n",
       "        [  80.3034],\n",
       "        [  69.6496],\n",
       "        [  28.1444],\n",
       "        [   9.7630],\n",
       "        [  41.1250],\n",
       "        [ 176.9283],\n",
       "        [   9.5598],\n",
       "        [  -4.4046],\n",
       "        [ -24.0359],\n",
       "        [  19.1701],\n",
       "        [ 102.4833],\n",
       "        [ 101.5209],\n",
       "        [ -58.5132],\n",
       "        [  17.6877],\n",
       "        [  63.0537],\n",
       "        [-102.3673],\n",
       "        [  -1.6586],\n",
       "        [  64.6626],\n",
       "        [ -44.1299],\n",
       "        [ 117.9966],\n",
       "        [  -4.6317],\n",
       "        [ -76.7146],\n",
       "        [ -67.2816],\n",
       "        [ -12.4644],\n",
       "        [  24.2973],\n",
       "        [  31.4312],\n",
       "        [  34.4411],\n",
       "        [ -74.7682],\n",
       "        [ 160.9960],\n",
       "        [  40.6977],\n",
       "        [  33.4340]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_features = X.shape\n",
    "X.shape\n",
    "print(n_features)\n",
    "print(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-126.2492],\n",
      "        [  50.9288],\n",
      "        [  63.1546],\n",
      "        [   6.0547],\n",
      "        [  -5.7295],\n",
      "        [  -2.7519],\n",
      "        [  58.7036],\n",
      "        [  53.8136],\n",
      "        [ -95.3411],\n",
      "        [  24.6481],\n",
      "        [ -59.4170],\n",
      "        [ -73.4235],\n",
      "        [-104.1627],\n",
      "        [  31.8077],\n",
      "        [ 171.1535],\n",
      "        [ -67.7520],\n",
      "        [ 141.4677],\n",
      "        [ -24.3676],\n",
      "        [  -2.1124],\n",
      "        [ -32.5958],\n",
      "        [ -29.4151],\n",
      "        [ -37.8715],\n",
      "        [-101.8983],\n",
      "        [  46.4129],\n",
      "        [-181.3484],\n",
      "        [ -31.7740],\n",
      "        [  24.1315],\n",
      "        [ 163.9438],\n",
      "        [  10.7737],\n",
      "        [  37.3589],\n",
      "        [   0.9804],\n",
      "        [-120.8857],\n",
      "        [ 138.1994],\n",
      "        [   9.2027],\n",
      "        [ -16.2069],\n",
      "        [  33.2171],\n",
      "        [ -45.6170],\n",
      "        [  -1.7776],\n",
      "        [-105.5628],\n",
      "        [   5.2639],\n",
      "        [  89.5979],\n",
      "        [ 146.1030],\n",
      "        [ -77.7870],\n",
      "        [  -3.8089],\n",
      "        [  60.8120],\n",
      "        [ -97.2027],\n",
      "        [  -1.1599],\n",
      "        [ -43.8825],\n",
      "        [  15.7428],\n",
      "        [ -24.2745],\n",
      "        [ -90.6015],\n",
      "        [ -19.0731],\n",
      "        [-101.7900],\n",
      "        [ -56.5514],\n",
      "        [  52.1697],\n",
      "        [-158.2847],\n",
      "        [  64.5397],\n",
      "        [  84.5210],\n",
      "        [  66.4343],\n",
      "        [  36.8660],\n",
      "        [  37.4378],\n",
      "        [ -82.9171],\n",
      "        [ -21.4183],\n",
      "        [  -5.5435],\n",
      "        [  59.8845],\n",
      "        [   8.3785],\n",
      "        [ -17.1763],\n",
      "        [-160.5090],\n",
      "        [-100.7372],\n",
      "        [  80.3034],\n",
      "        [  69.6496],\n",
      "        [  28.1444],\n",
      "        [   9.7630],\n",
      "        [  41.1250],\n",
      "        [ 176.9283],\n",
      "        [   9.5598],\n",
      "        [  -4.4046],\n",
      "        [ -24.0359],\n",
      "        [  19.1701],\n",
      "        [ 102.4833],\n",
      "        [ 101.5209],\n",
      "        [ -58.5132],\n",
      "        [  17.6877],\n",
      "        [  63.0537],\n",
      "        [-102.3673],\n",
      "        [  -1.6586],\n",
      "        [  64.6626],\n",
      "        [ -44.1299],\n",
      "        [ 117.9966],\n",
      "        [  -4.6317],\n",
      "        [ -76.7146],\n",
      "        [ -67.2816],\n",
      "        [ -12.4644],\n",
      "        [  24.2973],\n",
      "        [  31.4312],\n",
      "        [  34.4411],\n",
      "        [ -74.7682],\n",
      "        [ 160.9960],\n",
      "        [  40.6977],\n",
      "        [  33.4340]])\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-126.24922408781046,\n",
       " 50.92876904325736,\n",
       " 63.154633021922386,\n",
       " 6.0547200864738375,\n",
       " -5.729540250573546,\n",
       " -2.7519176884175236,\n",
       " 58.703559231999456,\n",
       " 53.81362958288187,\n",
       " -95.34105851183199,\n",
       " 24.64812470939173,\n",
       " -59.41697405621463,\n",
       " -73.423496188166,\n",
       " -104.16266749164922,\n",
       " 31.80766771985798,\n",
       " 171.15350154382287,\n",
       " -67.75196496665721,\n",
       " 141.46769810857572,\n",
       " -24.367569727471952,\n",
       " -2.112400965158713,\n",
       " -32.59583109463834,\n",
       " -29.415058193041002,\n",
       " -37.871459893797656,\n",
       " -101.89829600633351,\n",
       " 46.4128778382706,\n",
       " -181.34840043973222,\n",
       " -31.773995042999637,\n",
       " 24.1315487857442,\n",
       " 163.9438514385304,\n",
       " 10.773671108563668,\n",
       " 37.3589153231352,\n",
       " 0.9803670329602028,\n",
       " -120.88573187580702,\n",
       " 138.19938796923478,\n",
       " 9.202679031137727,\n",
       " -16.206889896630774,\n",
       " 33.21708479093532,\n",
       " -45.61698487997882,\n",
       " -1.7775890826236296,\n",
       " -105.56283971056314,\n",
       " 5.263946246750672,\n",
       " 89.5978923010736,\n",
       " 146.1030043897126,\n",
       " -77.78704394495927,\n",
       " -3.8089360671080916,\n",
       " 60.81195812269342,\n",
       " -97.20271029733965,\n",
       " -1.1598933445644217,\n",
       " -43.88245963821842,\n",
       " 15.742784045358636,\n",
       " -24.274465507389515,\n",
       " -90.60148118362483,\n",
       " -19.073145392033204,\n",
       " -101.79001521221232,\n",
       " -56.5514006727802,\n",
       " 52.169697896577084,\n",
       " -158.28468927827444,\n",
       " 64.53968736014687,\n",
       " 84.52102913163205,\n",
       " 66.43434450812964,\n",
       " 36.86598296695468,\n",
       " 37.43779493709346,\n",
       " -82.9171334053043,\n",
       " -21.418316098129726,\n",
       " -5.543483382000147,\n",
       " 59.88451572855597,\n",
       " 8.378489404086842,\n",
       " -17.176348938512554,\n",
       " -160.50895428089797,\n",
       " -100.73717846086919,\n",
       " 80.3033589405438,\n",
       " 69.64956653448208,\n",
       " 28.144435178463965,\n",
       " 9.763047402777984,\n",
       " 41.12497398757988,\n",
       " 176.9283139349499,\n",
       " 9.559817050409062,\n",
       " -4.404632763401551,\n",
       " -24.035852020639314,\n",
       " 19.170107303651854,\n",
       " 102.48327018169746,\n",
       " 101.52088195006564,\n",
       " -58.51318401695257,\n",
       " 17.687689612935436,\n",
       " 63.053667526459414,\n",
       " -102.36728191075137,\n",
       " -1.6585649368566635,\n",
       " 64.66264562248895,\n",
       " -44.12991149762253,\n",
       " 117.99658350579895,\n",
       " -4.631681521077392,\n",
       " -76.71464298692023,\n",
       " -67.28158730140012,\n",
       " -12.464351707014261,\n",
       " 24.29735070382985,\n",
       " 31.431200854774467,\n",
       " 34.4410832198471,\n",
       " -74.76820337705732,\n",
       " 160.99602124919886,\n",
       " 40.69772522191583,\n",
       " 33.434017675805066]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_numpy.tolist() #important to be considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "number_samples, n_features=X.shape\n",
    "print(number_samples)\n",
    "print(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and dataloader: but it runs while using command prompt based on pyto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# here it shows the error, due to pytorch version 1.0.1\n",
    "\n",
    "# Check the file:\n",
    "\n",
    "# C:\\Users\\2304373.UNIPHOREIND\\Pictures\\pytorch_tutorial_python_engineer\\pytorchTutorial-master\\data\\pytorch_ex.py\n",
    "\n",
    "# by running the code in anaconda prompt and navigating to the foldera with executing under environment variable, pyto. it works well try it due to pytorch 1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-4b752f42afec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mWineDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m# Initialize data, download, etc.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m# read with numpy or pandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize data, download, etc.\n",
    "        # read with numpy or pandas\n",
    "        xy = np.loadtxt('C:\\\\Users\\\\2304373.UNIPHOREIND\\\\Pictures\\\\pytorch_tutorial_python_engineer\\\\pytorchTutorial-master\\\\data\\\\winewine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
    "        self.n_samples = xy.shape[0]\n",
    "\n",
    "        # here the first column is the class label, the rest are the features\n",
    "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
    "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "# create dataset\n",
    "dataset = WineDataset()\n",
    "\n",
    "# get first sample and unpack\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nltk check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking with dummy data for fully connected layer correctly work first example-python engineer channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(60,60).view(1,1,60,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1, 6, 5)\n",
    "pool = nn.MaxPool2d(2, 2)\n",
    "conv2 = nn.Conv2d(6, 16, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 60, 60])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=conv1(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 56, 56])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 28, 28])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=conv2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 24, 24])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 12, 12])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 60, 60])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(60,60).view(1,1,60,60)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Also we can follow this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 60, 60])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Also we can follow this\n",
    "\n",
    "x=torch.rand(1,1,60,60)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = x.reshape(x.shape[0], -1)\n",
    "#x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 12 * 12, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
    "        x = x.view(-1, 16 * 12 * 12)            # -> n, 400\n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 10\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0335,  0.0860,  0.1078, -0.0222,  0.0168,  0.0373,  0.1296,  0.0553,\n",
       "         -0.0719, -0.0168]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking with dummy data for fully connected layer (another example) -sentdex CNN example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 50, 50])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(50,50).view(-1,1,50,50)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(1, 32, 5)\n",
    "pool = nn.MaxPool2d(2, 2)\n",
    "conv2 = nn.Conv2d(32, 64, 5)\n",
    "conv3 = nn.Conv2d(64, 128, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 46, 46])\n",
      "torch.Size([1, 32, 23, 23])\n",
      "torch.Size([1, 64, 19, 19])\n",
      "torch.Size([1, 64, 9, 9])\n",
      "torch.Size([1, 128, 5, 5])\n",
      "torch.Size([1, 128, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x=conv1(x)\n",
    "print(x.shape)\n",
    "x=pool(x)\n",
    "print(x.shape)\n",
    "x=conv2(x)\n",
    "print(x.shape)\n",
    "x=pool(x)\n",
    "print(x.shape)\n",
    "x=conv3(x)\n",
    "print(x.shape)\n",
    "x=pool(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 50, 50])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(50,50).view(-1,1,50,50)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        #self.fc1 = nn.Linear(64*9*9, 512) 2 layers CNN\n",
    "        self.fc1 = nn.Linear(128*2*2, 512)\n",
    "        self.fc2 = nn.Linear(512, 2) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "       \n",
    "        #x = x.view(-1,64*9*9)  2 layers CNN\n",
    "        x = x.view(-1,128*2*2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4828, 0.5172]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.view(4,1,25,25) # reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 25, 25])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 25, 25])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeeze the dimensions helpful and important in RNN (pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 60, 60])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(1,1,60,60)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 28, 28])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(4,1,28,28)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=torch.squeeze(x,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 28, 28])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can also squeeze like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 28, 28])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(4,1,28,28)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 28, 28])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning-Aladdin Persson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG_net(\n",
      "  (conv_layers): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU()\n",
      "    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU()\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU()\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU()\n",
      "    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU()\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU()\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU()\n",
      "    (33): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU()\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU()\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU()\n",
      "    (43): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fcs): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "\n",
    "VGG_types = {\n",
    "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"VGG16\": [\n",
    "        64,\n",
    "        64,\n",
    "        \"M\",\n",
    "        128,\n",
    "        128,\n",
    "        \"M\",\n",
    "        256,\n",
    "        256,\n",
    "        256,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "    ],\n",
    "    \"VGG19\": [\n",
    "        64,\n",
    "        64,\n",
    "        \"M\",\n",
    "        128,\n",
    "        128,\n",
    "        \"M\",\n",
    "        256,\n",
    "        256,\n",
    "        256,\n",
    "        256,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG_net(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1000):\n",
    "        super(VGG_net, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_layers = self.create_conv_layers(VGG_types[\"VGG16\"])\n",
    "\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fcs(x)\n",
    "        return x\n",
    "\n",
    "    def create_conv_layers(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for x in architecture:\n",
    "            if type(x) == int:\n",
    "                out_channels = x\n",
    "\n",
    "                layers += [\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        kernel_size=(3, 3),\n",
    "                        stride=(1, 1),\n",
    "                        padding=(1, 1),\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(x),\n",
    "                    nn.ReLU(),\n",
    "                ]\n",
    "                in_channels = x\n",
    "            elif x == \"M\":\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = VGG_net(in_channels=3, num_classes=1000).to(device)\n",
    "    print(model)\n",
    "    ## N = 3 (Mini batch size)\n",
    "    # x = torch.randn(3, 3, 224, 224).to(device)\n",
    "    # print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 7, 7])\n",
      "torch.Size([3, 1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 3, 224, 224).to(device)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=8,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=8,\n",
    "            out_channels=16,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 56 * 56, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        print(x.shape)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on MNIST dataset check\n",
    "x = torch.randn(1, 1, 28, 28).to(device)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 224, 224])\n",
      "torch.Size([1, 16, 56, 56])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 224, 224).to(device)\n",
    "print(x.shape)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python Engineer channel easy trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*12*12, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        print(x.shape)\n",
    "        x = x.view(-1, 16*12*12)            \n",
    "        x = F.relu(self.fc1(x))              \n",
    "        x = F.relu(self.fc2(x))               \n",
    "        x = self.fc3(x)                      \n",
    "        return x\n",
    "\n",
    "\n",
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 60, 60])\n",
      "torch.Size([1, 16, 12, 12])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 60, 60).to(device)\n",
    "print(x.shape)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
