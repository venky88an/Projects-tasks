{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-3.0.0-bin-hadoop2.7\\\\spark-3.0.0-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing pyspark installation\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate Spark Context\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = pyspark.SparkConf().setAppName('SparkApp').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 8, 27, 64]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example Test Code\n",
    "numeric_val = sc.parallelize([1,2,3,4])\n",
    "numeric_val.map(lambda x: x*x*x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: [Hi, I, heard, about, Spark] => \n",
      "Vector: [0.031109690852463248,-0.020681756734848025,0.009653565101325513]\n",
      "\n",
      "Text: [I, wish, Java, could, use, case, classes] => \n",
      "Vector: [0.01842194888740778,0.03821451057280813,0.06269602593965828]\n",
      "\n",
      "Text: [Logistic, regression, models, are, neat] => \n",
      "Vector: [-0.005502792075276375,0.001944764330983162,0.008235244452953339]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Input data: Each row is a bag of words from a sentence or document.\n",
    "documentDF = spark.createDataFrame([\n",
    "    (\"Hi I heard about Spark\".split(\" \"), ),\n",
    "    (\"I wish Java could use case classes\".split(\" \"), ),\n",
    "    (\"Logistic regression models are neat\".split(\" \"), )\n",
    "], [\"text\"])\n",
    "\n",
    "# Learn a mapping from words to Vectors.\n",
    "word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"text\", outputCol=\"result\")\n",
    "model = word2Vec.fit(documentDF)\n",
    "\n",
    "result = model.transform(documentDF)\n",
    "for row in result.collect():\n",
    "    text, vector = row\n",
    "    print(\"Text: [%s] => \\nVector: %s\\n\" % (\", \".join(text), str(vector)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Krish exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark= SparkSession.builder.appName('Customers').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://UNILP068.uniphoreind.local:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x217213a14a8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=spark.read.csv(\"C:\\\\Users\\\\2304373.UNIPHOREIND\\\\Pictures\\\\pyspark_exercises\\\\PysparkRegressions-master\\\\Ecommerce_Customers.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Email: string, Address: string, Avg Session Length: double, Time on App: double, Time on Website: double, Length of Membership: double, Yearly Amount Spent: double]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+-----------+---------------+--------------------+-------------------+\n",
      "|               Email|             Address|Avg Session Length|Time on App|Time on Website|Length of Membership|Yearly Amount Spent|\n",
      "+--------------------+--------------------+------------------+-----------+---------------+--------------------+-------------------+\n",
      "|mstephenson@ferna...|835 Frank TunnelW...|       34.49726773|12.65565115|    39.57766802|         4.082620633|         587.951054|\n",
      "|   hduke@hotmail.com|4547 Archer Commo...|       31.92627203|11.10946073|    37.26895887|         2.664034182|        392.2049334|\n",
      "|    pallen@yahoo.com|24645 Valerie Uni...|       33.00091476|11.33027806|    37.11059744|         4.104543202|        487.5475049|\n",
      "|riverarebecca@gma...|1414 David Throug...|       34.30555663|13.71751367|    36.72128268|         3.120178783|         581.852344|\n",
      "|mstephens@davidso...|14023 Rodriguez P...|       33.33067252|12.79518855|     37.5366533|         4.446308318|         599.406092|\n",
      "|alvareznancy@luca...|645 Martha Park A...|       33.87103788|12.02692534|    34.47687763|         5.493507201|        637.1024479|\n",
      "|katherine20@yahoo...|68388 Reyes Light...|        32.0215955|11.36634831|    36.68377615|         4.685017247|        521.5721748|\n",
      "|  awatkins@yahoo.com|Unit 6538 Box 898...|       32.73914294|12.35195897|    37.37335886|         4.434273435|        549.9041461|\n",
      "|vchurch@walter-ma...|860 Lee KeyWest D...|        33.9877729|13.38623528|    37.53449734|         3.273433578|         570.200409|\n",
      "|    bonnie69@lin.biz|PSC 2734, Box 525...|       31.93654862|11.81412829|    37.14516822|         3.202806072|        427.1993849|\n",
      "|andrew06@peterson...|26104 Alexander G...|       33.99257277|13.33897545|    37.22580613|         2.482607771|        492.6060127|\n",
      "|ryanwerner@freema...|Unit 2413 Box 034...|       33.87936082|  11.584783|    37.08792607|         3.713209203|        522.3374046|\n",
      "|   knelson@gmail.com|6705 Miller Orcha...|       29.53242897| 10.9612984|    37.42021558|         4.046423164|        408.6403511|\n",
      "|wrightpeter@yahoo...|05302 Dunlap Ferr...|       33.19033404|12.95922609|     36.1446667|         3.918541839|        573.4158673|\n",
      "|taylormason@gmail...|7773 Powell Sprin...|       32.38797585|13.14872569|    36.61995708|         2.494543647|        470.4527333|\n",
      "| jstark@anderson.com|49558 Ramirez Roa...|       30.73772037|12.63660605|    36.21376309|         3.357846842|        461.7807422|\n",
      "| wjennings@gmail.com|6362 Wilson Mount...|        32.1253869|11.73386169|    34.89409275|         3.136132716|        457.8476959|\n",
      "|rebecca45@hale-ba...|8982 Burton RowWi...|       32.33889932|12.01319469|    38.38513659|         2.420806161|        407.7045475|\n",
      "|alejandro75@hotma...|64475 Andre Club ...|       32.18781205|14.71538754|    38.24411459|         1.516575581|        452.3156755|\n",
      "|samuel46@love-wes...|544 Alexander Hei...|       32.61785606|13.98959256|     37.1905038|          4.06454855|        605.0610388|\n",
      "+--------------------+--------------------+------------------+-----------+---------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show() # like head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Email: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- Avg Session Length: double (nullable = true)\n",
      " |-- Time on App: double (nullable = true)\n",
      " |-- Time on Website: double (nullable = true)\n",
      " |-- Length of Membership: double (nullable = true)\n",
      " |-- Yearly Amount Spent: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureassembler=VectorAssembler(inputCols=[\"Avg Session Length\",\"Time on App\",\"Time on Website\",\"Length of Membership\"],outputCol=\"Independent Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=featureassembler.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+-----------+---------------+--------------------+-------------------+--------------------+\n",
      "|               Email|             Address|Avg Session Length|Time on App|Time on Website|Length of Membership|Yearly Amount Spent|Independent Features|\n",
      "+--------------------+--------------------+------------------+-----------+---------------+--------------------+-------------------+--------------------+\n",
      "|mstephenson@ferna...|835 Frank TunnelW...|       34.49726773|12.65565115|    39.57766802|         4.082620633|         587.951054|[34.49726773,12.6...|\n",
      "|   hduke@hotmail.com|4547 Archer Commo...|       31.92627203|11.10946073|    37.26895887|         2.664034182|        392.2049334|[31.92627203,11.1...|\n",
      "|    pallen@yahoo.com|24645 Valerie Uni...|       33.00091476|11.33027806|    37.11059744|         4.104543202|        487.5475049|[33.00091476,11.3...|\n",
      "|riverarebecca@gma...|1414 David Throug...|       34.30555663|13.71751367|    36.72128268|         3.120178783|         581.852344|[34.30555663,13.7...|\n",
      "|mstephens@davidso...|14023 Rodriguez P...|       33.33067252|12.79518855|     37.5366533|         4.446308318|         599.406092|[33.33067252,12.7...|\n",
      "|alvareznancy@luca...|645 Martha Park A...|       33.87103788|12.02692534|    34.47687763|         5.493507201|        637.1024479|[33.87103788,12.0...|\n",
      "|katherine20@yahoo...|68388 Reyes Light...|        32.0215955|11.36634831|    36.68377615|         4.685017247|        521.5721748|[32.0215955,11.36...|\n",
      "|  awatkins@yahoo.com|Unit 6538 Box 898...|       32.73914294|12.35195897|    37.37335886|         4.434273435|        549.9041461|[32.73914294,12.3...|\n",
      "|vchurch@walter-ma...|860 Lee KeyWest D...|        33.9877729|13.38623528|    37.53449734|         3.273433578|         570.200409|[33.9877729,13.38...|\n",
      "|    bonnie69@lin.biz|PSC 2734, Box 525...|       31.93654862|11.81412829|    37.14516822|         3.202806072|        427.1993849|[31.93654862,11.8...|\n",
      "|andrew06@peterson...|26104 Alexander G...|       33.99257277|13.33897545|    37.22580613|         2.482607771|        492.6060127|[33.99257277,13.3...|\n",
      "|ryanwerner@freema...|Unit 2413 Box 034...|       33.87936082|  11.584783|    37.08792607|         3.713209203|        522.3374046|[33.87936082,11.5...|\n",
      "|   knelson@gmail.com|6705 Miller Orcha...|       29.53242897| 10.9612984|    37.42021558|         4.046423164|        408.6403511|[29.53242897,10.9...|\n",
      "|wrightpeter@yahoo...|05302 Dunlap Ferr...|       33.19033404|12.95922609|     36.1446667|         3.918541839|        573.4158673|[33.19033404,12.9...|\n",
      "|taylormason@gmail...|7773 Powell Sprin...|       32.38797585|13.14872569|    36.61995708|         2.494543647|        470.4527333|[32.38797585,13.1...|\n",
      "| jstark@anderson.com|49558 Ramirez Roa...|       30.73772037|12.63660605|    36.21376309|         3.357846842|        461.7807422|[30.73772037,12.6...|\n",
      "| wjennings@gmail.com|6362 Wilson Mount...|        32.1253869|11.73386169|    34.89409275|         3.136132716|        457.8476959|[32.1253869,11.73...|\n",
      "|rebecca45@hale-ba...|8982 Burton RowWi...|       32.33889932|12.01319469|    38.38513659|         2.420806161|        407.7045475|[32.33889932,12.0...|\n",
      "|alejandro75@hotma...|64475 Andre Club ...|       32.18781205|14.71538754|    38.24411459|         1.516575581|        452.3156755|[32.18781205,14.7...|\n",
      "|samuel46@love-wes...|544 Alexander Hei...|       32.61785606|13.98959256|     37.1905038|          4.06454855|        605.0610388|[32.61785606,13.9...|\n",
      "+--------------------+--------------------+------------------+-----------+---------------+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|Independent Features|\n",
      "+--------------------+\n",
      "|[34.49726773,12.6...|\n",
      "|[31.92627203,11.1...|\n",
      "|[33.00091476,11.3...|\n",
      "|[34.30555663,13.7...|\n",
      "|[33.33067252,12.7...|\n",
      "|[33.87103788,12.0...|\n",
      "|[32.0215955,11.36...|\n",
      "|[32.73914294,12.3...|\n",
      "|[33.9877729,13.38...|\n",
      "|[31.93654862,11.8...|\n",
      "|[33.99257277,13.3...|\n",
      "|[33.87936082,11.5...|\n",
      "|[29.53242897,10.9...|\n",
      "|[33.19033404,12.9...|\n",
      "|[32.38797585,13.1...|\n",
      "|[30.73772037,12.6...|\n",
      "|[32.1253869,11.73...|\n",
      "|[32.33889932,12.0...|\n",
      "|[32.18781205,14.7...|\n",
      "|[32.61785606,13.9...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select(\"Independent Features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_data=output.select(\"Independent Features\",\"Yearly Amount Spent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|Independent Features|Yearly Amount Spent|\n",
      "+--------------------+-------------------+\n",
      "|[34.49726773,12.6...|         587.951054|\n",
      "|[31.92627203,11.1...|        392.2049334|\n",
      "|[33.00091476,11.3...|        487.5475049|\n",
      "|[34.30555663,13.7...|         581.852344|\n",
      "|[33.33067252,12.7...|         599.406092|\n",
      "|[33.87103788,12.0...|        637.1024479|\n",
      "|[32.0215955,11.36...|        521.5721748|\n",
      "|[32.73914294,12.3...|        549.9041461|\n",
      "|[33.9877729,13.38...|         570.200409|\n",
      "|[31.93654862,11.8...|        427.1993849|\n",
      "|[33.99257277,13.3...|        492.6060127|\n",
      "|[33.87936082,11.5...|        522.3374046|\n",
      "|[29.53242897,10.9...|        408.6403511|\n",
      "|[33.19033404,12.9...|        573.4158673|\n",
      "|[32.38797585,13.1...|        470.4527333|\n",
      "|[30.73772037,12.6...|        461.7807422|\n",
      "|[32.1253869,11.73...|        457.8476959|\n",
      "|[32.33889932,12.0...|        407.7045475|\n",
      "|[32.18781205,14.7...|        452.3156755|\n",
      "|[32.61785606,13.9...|        605.0610388|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=finalized_data.randomSplit([0.75,0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=LinearRegression(featuresCol='Independent Features', labelCol='Yearly Amount Spent')\n",
    "regressor=regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([26.064, 38.733, 0.3046, 61.1358])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1056.151739932916"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results=regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------------------+\n",
      "|Independent Features|Yearly Amount Spent|        prediction|\n",
      "+--------------------+-------------------+------------------+\n",
      "|[30.97167564,11.7...|        494.6386098|  487.083082865684|\n",
      "|[31.06132516,12.3...|        487.5554581|  493.100253191707|\n",
      "|[31.12809005,13.2...|        557.2526867| 563.7121488618864|\n",
      "|[31.1695068,13.97...|        427.3565308| 417.6667401588868|\n",
      "|[31.30919264,11.9...|        432.7207178|429.63783382347697|\n",
      "|[31.44744649,10.1...|        418.6027421|425.46115441307984|\n",
      "|[31.5171218,10.74...|        275.9184207|280.67240719261827|\n",
      "|[31.66104982,11.3...|        416.3583536| 417.2269130360196|\n",
      "|[31.8209982,10.77...|         424.675281|416.92115882747635|\n",
      "|[31.82934646,11.2...|         385.152338|384.32590664061104|\n",
      "|[31.87455169,10.2...|        392.2852442| 397.8827530299618|\n",
      "|[31.8854063,11.28...|         390.103273|399.18198762115594|\n",
      "|[31.90962683,11.3...|        563.4460357| 551.0163389166153|\n",
      "|[31.92627203,11.1...|        392.2049334|380.49777679700264|\n",
      "|[32.03054972,12.6...|        594.2744834| 588.0250534081042|\n",
      "|[32.05426185,13.1...|        561.8746577| 556.6078088153174|\n",
      "|[32.09610899,10.8...|        375.3984554| 375.3311237864175|\n",
      "|[32.1223648,11.43...|        528.9336186| 531.7347191789834|\n",
      "|[32.14906052,10.0...|        392.9922559|398.39036714276426|\n",
      "|[32.17550124,13.3...|        588.7126055|  577.397885067573|\n",
      "|[32.19249883,13.3...|         616.660286| 619.0176014631609|\n",
      "|[32.20465465,12.4...|         478.584286|478.61610417635825|\n",
      "|[32.22729914,13.7...|        613.5993234| 620.7586656488425|\n",
      "|[32.23014912,11.0...|        517.1651356| 513.5956391402701|\n",
      "|[32.2559012,10.48...|        479.7319376|477.85585884231955|\n",
      "|[32.27184828,13.4...|          511.97986| 507.4207944633795|\n",
      "|[32.28312306,10.9...|        524.6379646|511.35075596010165|\n",
      "|[32.34279623,11.4...|        486.0834255| 476.4032793147212|\n",
      "|[32.35147815,13.1...|        532.9352188| 528.1217504750355|\n",
      "|[32.36312129,12.4...|        570.6300981| 566.6688497365556|\n",
      "|[32.37798966,11.9...|        408.2169018| 435.7773453687996|\n",
      "|[32.38625186,10.6...|        418.1500811|420.95692194113235|\n",
      "|[32.38845163,11.0...|        424.7626355| 442.8291387615816|\n",
      "|[32.43075793,11.3...|        408.6201878| 408.4539485478017|\n",
      "|[32.4914466,12.53...|        449.0703194|438.96166632793756|\n",
      "|[32.49719846,12.8...|         493.719193| 481.0979825941654|\n",
      "|[32.52976873,11.7...|        298.7620079| 306.9826194875491|\n",
      "|[32.53379686,12.2...|        485.9231305| 500.5923748002624|\n",
      "|[32.5367749,11.12...|        510.5394217|  486.360314704202|\n",
      "|[32.56723048,12.4...|        537.8461953| 545.6387962763129|\n",
      "+--------------------+-------------------+------------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing example files in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-3.0.0-bin-hadoop2.7\\\\spark-3.0.0-bin-hadoop2.7'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing pyspark installation\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "# Loads data.\n",
    "dataset = spark.read.format(\"libsvm\").load(\"C:\\\\spark-3.0.0-bin-hadoop2.7\\\\spark-3.0.0-bin-hadoop2.7\\\\data\\\\mllib\\\\sample_lda_libsvm_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -820.7717059783324\n",
      "The upper bound on perplexity: 3.156814253762817\n",
      "The topics described by their top-weighted terms:\n",
      "+-----+-----------+---------------------------------------------------------------+\n",
      "|topic|termIndices|termWeights                                                    |\n",
      "+-----+-----------+---------------------------------------------------------------+\n",
      "|0    |[0, 3, 5]  |[0.0988907776639746, 0.09840811080140031, 0.09815784171623272] |\n",
      "|1    |[1, 4, 9]  |[0.17372581481263155, 0.1541451633717008, 0.14809304265019235] |\n",
      "|2    |[1, 2, 0]  |[0.10763518719710427, 0.09290001778648123, 0.09285769471788125]|\n",
      "|3    |[1, 7, 8]  |[0.10278233443057151, 0.10257897851841583, 0.09964766524551634]|\n",
      "|4    |[6, 7, 1]  |[0.10991496236314273, 0.10762017498569953, 0.0934346815074767] |\n",
      "|5    |[8, 2, 6]  |[0.10265802360235843, 0.10194550822222663, 0.09453499013679116]|\n",
      "|6    |[3, 7, 8]  |[0.1061840707195339, 0.10315547141829495, 0.09803871726311048] |\n",
      "|7    |[1, 3, 8]  |[0.11474302117107452, 0.10514280835548424, 0.10259971291271291]|\n",
      "|8    |[3, 5, 10] |[0.2374930746555663, 0.11348952620811312, 0.09962569253007822] |\n",
      "|9    |[5, 7, 4]  |[0.18183760328492327, 0.1272661979270135, 0.10325452478598535] |\n",
      "+-----+-----------+---------------------------------------------------------------+\n",
      "\n",
      "+-----+---------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|features                                                       |topicDistribution                                                                                                                                                                                                     |\n",
      "+-----+---------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|0.0  |(11,[0,1,2,4,5,6,7,10],[1.0,2.0,6.0,2.0,3.0,1.0,1.0,3.0])      |[0.004787764381175711,0.5615101619045726,0.004787660082208542,0.004787719858343381,0.0047876238709913385,0.004787699509230767,0.004787635136648656,0.004787615280546142,0.4001018563013752,0.004874263674907718]      |\n",
      "|1.0  |(11,[0,1,3,4,7,10],[1.0,3.0,1.0,3.0,2.0,1.0])                  |[0.007985896146011619,0.9275275970960765,0.007985799333177107,0.007985782534135325,0.007985905318935114,0.007985687320196269,0.007985918941680534,0.007985834515569687,0.00844151528187408,0.008130063512343886]      |\n",
      "|2.0  |(11,[0,1,2,5,6,8,9],[1.0,4.0,1.0,4.0,9.0,1.0,2.0])             |[0.004162421972731108,0.9622258981229949,0.0041623856808792005,0.004162477918977179,0.00416252804343545,0.004162423129947515,0.004162305463257558,0.0041623623545329275,0.004399418252719282,0.004237779060524827]    |\n",
      "|3.0  |(11,[0,1,3,6,8,9,10],[2.0,1.0,3.0,5.0,2.0,3.0,9.0])            |[0.0036816869017514066,0.00411912112472916,0.003681635811606316,0.0036816667354038525,0.0036816920067286227,0.003681646534761874,0.003681612756208888,0.003681656489710401,0.9663612965100663,0.0037479851290331797]  |\n",
      "|4.0  |(11,[0,1,2,3,4,6,9,10],[3.0,1.0,1.0,9.0,3.0,2.0,1.0,3.0])      |[0.0039886731004388715,0.004461380878498459,0.003988620746373677,0.003988602958188689,0.003988629817708008,0.003988586951854319,0.003988622185419188,0.003988636076538189,0.9635576789817842,0.00406056830319631]     |\n",
      "|5.0  |(11,[0,1,3,4,5,6,7,8,9],[4.0,2.0,3.0,4.0,5.0,1.0,1.0,1.0,4.0]) |[0.0036815775047944086,0.7421743992923904,0.0036815128453886238,0.0036814987291391393,0.003681518490066734,0.0036814844720881243,0.00368151718637446,0.003681503533491267,0.2283067229951063,0.0037482649511605417]   |\n",
      "|6.0  |(11,[0,1,3,6,8,9,10],[2.0,1.0,3.0,5.0,2.0,2.0,9.0])            |[0.0038291067386040747,0.004283917433339309,0.0038290473455669855,0.0038290890538905963,0.003829110909311293,0.003829064418524488,0.003829024920122967,0.003829070416072991,0.9650145254657567,0.0038980432988106003] |\n",
      "|7.0  |(11,[0,1,2,3,4,5,6,9,10],[1.0,1.0,1.0,9.0,2.0,1.0,2.0,1.0,3.0])|[0.004351660077932654,0.004867088867485543,0.004351609221553831,0.004351586577855102,0.004351627556060317,0.004351574328360302,0.004351601943941633,0.004351628692063786,0.9602415143588647,0.004430108375882107]     |\n",
      "|8.0  |(11,[0,1,3,4,5,6,7],[4.0,4.0,3.0,4.0,2.0,1.0,3.0])             |[0.004351728669764955,0.7976518780547381,0.004351669435596715,0.004351676517280215,0.004351718451219565,0.00435161902087453,0.004351711405966235,0.004351659686035261,0.16745585692586845,0.0044304818326560145]      |\n",
      "|9.0  |(11,[0,1,2,4,6,8,9,10],[2.0,8.0,2.0,3.0,2.0,2.0,7.0,2.0])      |[0.0033003456255687146,0.9700500407305614,0.003300318485495377,0.003300330943171438,0.0033003171573646323,0.0033003147584315944,0.0033003027794211845,0.003300339863866519,0.003487889611460184,0.0033598000446587633]|\n",
      "|10.0 |(11,[0,1,2,3,5,6,9,10],[1.0,1.0,1.0,9.0,2.0,2.0,3.0,3.0])      |[0.00416225480431196,0.004655251919106215,0.0041622168944195044,0.004162180527848063,0.004162221867670201,0.004162171121736341,0.00416219148490979,0.004162218145679261,0.9619719587543559,0.004237334479962794]      |\n",
      "|11.0 |(11,[0,1,4,5,6,7,9],[4.0,1.0,4.0,5.0,1.0,3.0,1.0])             |[0.0047873869109550556,0.558900004704554,0.0047873215409030825,0.004787347779846984,0.004787371133493274,0.0047872965801239046,0.004787324515427377,0.004787262864334527,0.005059615329061524,0.40252906864130017]    |\n",
      "+-----+---------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trains a LDA model.\n",
    "lda = LDA(k=10, maxIter=10)\n",
    "model = lda.fit(dataset)\n",
    "\n",
    "ll = model.logLikelihood(dataset)\n",
    "lp = model.logPerplexity(dataset)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))\n",
    "\n",
    "# Describe topics.\n",
    "topics = model.describeTopics(3)\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "topics.show(truncate=False)\n",
    "\n",
    "# Shows the result\n",
    "transformed = model.transform(dataset)\n",
    "transformed.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI university (Linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('C:\\\\Users\\\\2304373.UNIPHOREIND\\\\Pictures\\\\pyspark_exercises\\\\Data_Science_Bootcamp-master\\\\Student_Grades_Data.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Time_to_Study: integer (nullable = true)\n",
      " |-- Grades: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|Time_to_Study|Grades|\n",
      "+-------------+------+\n",
      "|            1|   1.5|\n",
      "|            5|   2.7|\n",
      "|            7|   3.1|\n",
      "|            3|   2.1|\n",
      "|            2|   1.8|\n",
      "|            9|   3.9|\n",
      "|            6|   2.9|\n",
      "|           12|   4.5|\n",
      "|           11|   4.3|\n",
      "|            2|   1.8|\n",
      "|            4|   2.4|\n",
      "|            8|   3.5|\n",
      "|           13|   4.8|\n",
      "|            9|   3.9|\n",
      "|           14|   5.0|\n",
      "|           10|   4.1|\n",
      "|            6|   2.9|\n",
      "|           12|   4.5|\n",
      "|            1|   1.5|\n",
      "|            4|   2.4|\n",
      "+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display first few rows of data\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Feature array by omitting the last column\n",
    "feature_cols = data.columns[:-1] \n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vect_assembler = VectorAssembler(inputCols=feature_cols,outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilize Assembler created above in order to add the feature column\n",
    "data_w_features = vect_assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+--------+\n",
      "|Time_to_Study|Grades|features|\n",
      "+-------------+------+--------+\n",
      "|            1|   1.5|   [1.0]|\n",
      "|            5|   2.7|   [5.0]|\n",
      "|            7|   3.1|   [7.0]|\n",
      "|            3|   2.1|   [3.0]|\n",
      "|            2|   1.8|   [2.0]|\n",
      "|            9|   3.9|   [9.0]|\n",
      "|            6|   2.9|   [6.0]|\n",
      "|           12|   4.5|  [12.0]|\n",
      "|           11|   4.3|  [11.0]|\n",
      "|            2|   1.8|   [2.0]|\n",
      "|            4|   2.4|   [4.0]|\n",
      "|            8|   3.5|   [8.0]|\n",
      "|           13|   4.8|  [13.0]|\n",
      "|            9|   3.9|   [9.0]|\n",
      "|           14|   5.0|  [14.0]|\n",
      "|           10|   4.1|  [10.0]|\n",
      "|            6|   2.9|   [6.0]|\n",
      "|           12|   4.5|  [12.0]|\n",
      "|            1|   1.5|   [1.0]|\n",
      "|            4|   2.4|   [4.0]|\n",
      "+-------------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Display the data having additional column named features. Had it been multiple linear regression problem, you could see all the\n",
    "# independent variable values combined in one list\n",
    "data_w_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|features|Grades|\n",
      "+--------+------+\n",
      "|   [1.0]|   1.5|\n",
      "|   [5.0]|   2.7|\n",
      "|   [7.0]|   3.1|\n",
      "|   [3.0]|   2.1|\n",
      "|   [2.0]|   1.8|\n",
      "|   [9.0]|   3.9|\n",
      "|   [6.0]|   2.9|\n",
      "|  [12.0]|   4.5|\n",
      "|  [11.0]|   4.3|\n",
      "|   [2.0]|   1.8|\n",
      "|   [4.0]|   2.4|\n",
      "|   [8.0]|   3.5|\n",
      "|  [13.0]|   4.8|\n",
      "|   [9.0]|   3.9|\n",
      "|  [14.0]|   5.0|\n",
      "|  [10.0]|   4.1|\n",
      "|   [6.0]|   2.9|\n",
      "|  [12.0]|   4.5|\n",
      "|   [1.0]|   1.5|\n",
      "|   [4.0]|   2.4|\n",
      "+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Select only Features and Label from previous dataset as we need these two entities for building machine learning model\n",
    "finalized_data = data_w_features.select(\"features\",\"Grades\")\n",
    "\n",
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and test model with 70% obs. going in training and 30% in testing\n",
    "train_dataset, test_dataset = finalized_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            Grades|\n",
      "+-------+------------------+\n",
      "|  count|                38|\n",
      "|   mean|3.1657894736842107|\n",
      "| stddev|1.0710632039768841|\n",
      "|    min|               1.5|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Peek into training data\n",
    "train_dataset.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            Grades|\n",
      "+-------+------------------+\n",
      "|  count|                12|\n",
      "|   mean|               3.4|\n",
      "| stddev|1.2380336315008864|\n",
      "|    min|               1.5|\n",
      "|    max|               5.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Peek into test_dataset\n",
    "test_dataset.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Linear Regression class called LinearRegression\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Linear Regression object named having feature column as features and Label column as Time_to_Study\n",
    "LinReg = LinearRegression(featuresCol=\"features\", labelCol=\"Grades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model on the training using fit() method.\n",
    "model = LinReg.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the Grades using the evulate method\n",
    "pred = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------------------+\n",
      "|features|Grades|        prediction|\n",
      "+--------+------+------------------+\n",
      "|   [1.0]|   1.5|1.5572708476912447|\n",
      "|   [1.0]|   1.5|1.5572708476912447|\n",
      "|   [3.0]|   2.1|2.1005926946933133|\n",
      "|   [5.0]|   2.7|2.6439145416953815|\n",
      "|   [6.0]|   2.9| 2.915575465196416|\n",
      "|   [8.0]|   3.5|3.4588973121984843|\n",
      "|  [10.0]|   4.1|4.0022191592005525|\n",
      "|  [10.0]|   4.1|4.0022191592005525|\n",
      "|  [10.0]|   4.1|4.0022191592005525|\n",
      "|  [12.0]|   4.5| 4.545541006202621|\n",
      "|  [13.0]|   4.8| 4.817201929703655|\n",
      "|  [14.0]|   5.0|  5.08886285320469|\n",
      "+--------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show the predicted Grade values along side actual Grade values\n",
    "pred.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient of the model is : DenseVector([0.2717])\n"
     ]
    }
   ],
   "source": [
    "#Find out coefficient value\n",
    "coefficient = model.coefficients\n",
    "print (\"The coefficient of the model is : %a\" %coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Intercept of the model is : 1.285610\n"
     ]
    }
   ],
   "source": [
    "#Find out intercept Value\n",
    "intercept = model.intercept\n",
    "print (\"The Intercept of the model is : %f\" %intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.065\n",
      "MSE: 0.004\n",
      "MAE: 0.056\n",
      "r2: 0.997\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model using metric like Mean Absolute Error(MAE), Root Mean Square Error(RMSE) and R-Square\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluation = RegressionEvaluator(labelCol=\"Grades\", predictionCol=\"prediction\")\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"rmse\"})\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mse\"})\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"mae\"})\n",
    "print(\"MAE: %.3f\" % mae)\n",
    "\n",
    "# r2 - coefficient of determination\n",
    "r2 = evaluation.evaluate(pred.predictions, {evaluation.metricName: \"r2\"})\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Unlabeled dataset  to contain only feature column\n",
    "unlabeled_dataset = test_dataset.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|features|\n",
      "+--------+\n",
      "|   [1.0]|\n",
      "|   [1.0]|\n",
      "|   [3.0]|\n",
      "|   [5.0]|\n",
      "|   [6.0]|\n",
      "|   [8.0]|\n",
      "|  [10.0]|\n",
      "|  [10.0]|\n",
      "|  [10.0]|\n",
      "|  [12.0]|\n",
      "|  [13.0]|\n",
      "|  [14.0]|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display the content of unlabeled_dataset\n",
    "unlabeled_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the model output for fresh & unseen test data using transform() method\n",
    "new_predictions = model.transform(unlabeled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|features|        prediction|\n",
      "+--------+------------------+\n",
      "|   [1.0]|1.5572708476912447|\n",
      "|   [1.0]|1.5572708476912447|\n",
      "|   [3.0]|2.1005926946933133|\n",
      "|   [5.0]|2.6439145416953815|\n",
      "|   [6.0]| 2.915575465196416|\n",
      "|   [8.0]|3.4588973121984843|\n",
      "|  [10.0]|4.0022191592005525|\n",
      "|  [10.0]|4.0022191592005525|\n",
      "|  [10.0]|4.0022191592005525|\n",
      "|  [12.0]| 4.545541006202621|\n",
      "|  [13.0]| 4.817201929703655|\n",
      "|  [14.0]|  5.08886285320469|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Display the new prediction values\n",
    "new_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('C:\\\\Users\\\\2304373.UNIPHOREIND\\\\Pictures\\\\pyspark_exercises\\\\Data_Science_Bootcamp-master\\\\Regression_Algorithms\\\\Multiple_Linear_Regression\\\\Restaurant_Profit_Data.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Miscellaneous_Expenses: double (nullable = true)\n",
      " |-- Food_Innovation_Spend: double (nullable = true)\n",
      " |-- Advertising: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Profit: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------------+-----------+-------+---------+\n",
      "|Miscellaneous_Expenses|Food_Innovation_Spend|Advertising|   City|   Profit|\n",
      "+----------------------+---------------------+-----------+-------+---------+\n",
      "|              138671.8|             167497.2|   475918.1|Chicago|202443.83|\n",
      "|             153151.59|             164745.7|  448032.53| Mumbai|201974.06|\n",
      "|             102919.55|            155589.51|  412068.54|  Tokyo|201232.39|\n",
      "|             120445.85|            146520.41|  387333.62|Chicago|193083.99|\n",
      "|              93165.77|            144255.34|  370302.42|  Tokyo|176369.94|\n",
      "|             101588.71|             134024.9|  366995.36|Chicago|167173.12|\n",
      "|             148972.87|            136763.46|  131850.82| Mumbai|166304.51|\n",
      "|             147304.06|            132446.13|  328010.68|  Tokyo| 165934.6|\n",
      "|             150492.95|            122690.52|  315747.29|Chicago|162393.77|\n",
      "|             110453.17|            125482.88|  309115.62| Mumbai|159941.96|\n",
      "|             112368.11|            104061.08|  233294.95|  Tokyo|156303.95|\n",
      "|              93564.61|            102819.96|  253878.55| Mumbai| 154441.4|\n",
      "|             129094.38|             96011.75|  253973.44|  Tokyo|151767.52|\n",
      "|             137269.07|             94140.39|  256798.93| Mumbai|144489.35|\n",
      "|             158321.42|            122091.24|  260646.92|  Tokyo|142784.65|\n",
      "|             124390.84|            116671.61|  265910.23|Chicago|140099.04|\n",
      "|             123371.55|             80161.11|  268480.06| Mumbai|137174.93|\n",
      "|             146851.58|             96805.16|  286708.31|Chicago|135552.37|\n",
      "|             115949.79|             93897.16|  299053.57|  Tokyo| 134448.9|\n",
      "|             155288.11|              88567.7|     4134.0|Chicago|132958.86|\n",
      "+----------------------+---------------------+-----------+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Miscellaneous_Expenses', 'double'),\n",
       " ('Food_Innovation_Spend', 'double'),\n",
       " ('Advertising', 'double'),\n",
       " ('City', 'string'),\n",
       " ('Profit', 'double')]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display data types of the data columns.\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['City']\n",
      "['Miscellaneous_Expenses', 'Food_Innovation_Spend', 'Advertising']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [item[0] for item in data.dtypes if item[1].startswith('string')]\n",
    "print(categorical_cols)\n",
    "\n",
    "numerical_cols = [item[0] for item in data.dtypes if item[1].startswith('int') | item[1].startswith('double')][:-1]\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  categorical features\n",
      "3  numerical features\n"
     ]
    }
   ],
   "source": [
    "print(str(len(categorical_cols)) + '  categorical features')\n",
    "print(str(len(numerical_cols)) + '  numerical features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# replaced OneHotEncoderEstimator due to the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder # replaced OneHotEncoderEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler\n",
    "stages = []\n",
    "for categoricalCol in categorical_cols:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    OHencoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"_catVec\"])\n",
    "stages += [stringIndexer, OHencoder]\n",
    "assemblerInputs = [c + \"_catVec\" for c in categorical_cols] + numerical_cols\n",
    "Vectassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [Vectassembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do not run below code another time you will get error. if you get the error by running mistakely, execute from first importing data (Restaurant_Profit_Data.csv), then the error will be resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>Miscellaneous_Expenses</th>\n",
       "      <th>Food_Innovation_Spend</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>City</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.0, 0.0, 138671.8, 167497.2, 475918.1]</td>\n",
       "      <td>138671.80</td>\n",
       "      <td>167497.20</td>\n",
       "      <td>475918.10</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>202443.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 1.0, 153151.59, 164745.7, 448032.53]</td>\n",
       "      <td>153151.59</td>\n",
       "      <td>164745.70</td>\n",
       "      <td>448032.53</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>201974.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 102919.55, 155589.51, 412068.54]</td>\n",
       "      <td>102919.55</td>\n",
       "      <td>155589.51</td>\n",
       "      <td>412068.54</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>201232.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0, 0.0, 120445.85, 146520.41, 387333.62]</td>\n",
       "      <td>120445.85</td>\n",
       "      <td>146520.41</td>\n",
       "      <td>387333.62</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>193083.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 93165.77, 144255.34, 370302.42]</td>\n",
       "      <td>93165.77</td>\n",
       "      <td>144255.34</td>\n",
       "      <td>370302.42</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>176369.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      features  Miscellaneous_Expenses  \\\n",
       "0     [1.0, 0.0, 138671.8, 167497.2, 475918.1]               138671.80   \n",
       "1   [0.0, 1.0, 153151.59, 164745.7, 448032.53]               153151.59   \n",
       "2  [0.0, 0.0, 102919.55, 155589.51, 412068.54]               102919.55   \n",
       "3  [1.0, 0.0, 120445.85, 146520.41, 387333.62]               120445.85   \n",
       "4   [0.0, 0.0, 93165.77, 144255.34, 370302.42]                93165.77   \n",
       "\n",
       "   Food_Innovation_Spend  Advertising     City     Profit  \n",
       "0              167497.20    475918.10  Chicago  202443.83  \n",
       "1              164745.70    448032.53   Mumbai  201974.06  \n",
       "2              155589.51    412068.54    Tokyo  201232.39  \n",
       "3              146520.41    387333.62  Chicago  193083.99  \n",
       "4              144255.34    370302.42    Tokyo  176369.94  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "cols = data.columns\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(data)\n",
    "data = pipelineModel.transform(data)\n",
    "selectedCols = ['features']+cols\n",
    "data = data.select(selectedCols)\n",
    "pd.DataFrame(data.take(5), columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
