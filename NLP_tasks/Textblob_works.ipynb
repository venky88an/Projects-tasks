{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystr = \"\"\"The best error message is the one that never shows up.\n",
    "You Learn More From Failure Than From Success. \n",
    "Don’t Let It Stop You. Failure Builds Character.\n",
    "If You Are Working On Something That You Really Care About, You Don’t Have To Be Pushed. The Vision Pulls You.\n",
    "The purpose of software engineering is to control complexity, not to create it\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"The best error message is the one that never shows up.\n",
       "You Learn More From Failure Than From Success. \n",
       "Don’t Let It Stop You. Failure Builds Character.\n",
       "If You Are Working On Something That You Really Care About, You Don’t Have To Be Pushed. The Vision Pulls You.\n",
       "The purpose of software engineering is to control complexity, not to create it\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob # this is one of the data types like string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.TextBlob"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.blob import BaseBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_blob = BaseBlob(mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['The', 'best', 'error', 'message', 'is', 'the', 'one', 'that', 'never', 'shows', 'up', 'You', 'Learn', 'More', 'From', 'Failure', 'Than', 'From', 'Success', 'Don', '’', 't', 'Let', 'It', 'Stop', 'You', 'Failure', 'Builds', 'Character', 'If', 'You', 'Are', 'Working', 'On', 'Something', 'That', 'You', 'Really', 'Care', 'About', 'You', 'Don', '’', 't', 'Have', 'To', 'Be', 'Pushed', 'The', 'Vision', 'Pulls', 'You', 'The', 'purpose', 'of', 'software', 'engineering', 'is', 'to', 'control', 'complexity', 'not', 'to', 'create', 'it'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"The best error message is the one that never shows up.\"),\n",
       " Sentence(\"You Learn More From Failure Than From Success.\"),\n",
       " Sentence(\"Don’t Let It Stop You.\"),\n",
       " Sentence(\"Failure Builds Character.\"),\n",
       " Sentence(\"If You Are Working On Something That You Really Care About, You Don’t Have To Be Pushed.\"),\n",
       " Sentence(\"The Vision Pulls You.\"),\n",
       " Sentence(\"The purpose of software engineering is to control complexity, not to create it\")]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentences # sentence tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'best', 'error', 'message', 'is', 'the', 'one', 'that', 'never', 'shows', 'up']\n",
      "['You', 'Learn', 'More', 'From', 'Failure', 'Than', 'From', 'Success']\n",
      "['Don', '’', 't', 'Let', 'It', 'Stop', 'You']\n",
      "['Failure', 'Builds', 'Character']\n",
      "['If', 'You', 'Are', 'Working', 'On', 'Something', 'That', 'You', 'Really', 'Care', 'About', 'You', 'Don', '’', 't', 'Have', 'To', 'Be', 'Pushed']\n",
      "['The', 'Vision', 'Pulls', 'You']\n",
      "['The', 'purpose', 'of', 'software', 'engineering', 'is', 'to', 'control', 'complexity', 'not', 'to', 'create', 'it']\n"
     ]
    }
   ],
   "source": [
    "# Words tokens\n",
    "for word_tokens in blob.sentences:\n",
    "    print(word_tokens.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'best']\n",
      "['best', 'error']\n",
      "['error', 'message']\n",
      "['message', 'is']\n",
      "['is', 'the']\n",
      "['the', 'one']\n",
      "['one', 'that']\n",
      "['that', 'never']\n",
      "['never', 'shows']\n",
      "['shows', 'up']\n",
      "['up', 'You']\n",
      "['You', 'Learn']\n",
      "['Learn', 'More']\n",
      "['More', 'From']\n",
      "['From', 'Failure']\n",
      "['Failure', 'Than']\n",
      "['Than', 'From']\n",
      "['From', 'Success']\n",
      "['Success', 'Don']\n",
      "['Don', '’']\n",
      "['’', 't']\n",
      "['t', 'Let']\n",
      "['Let', 'It']\n",
      "['It', 'Stop']\n",
      "['Stop', 'You']\n",
      "['You', 'Failure']\n",
      "['Failure', 'Builds']\n",
      "['Builds', 'Character']\n",
      "['Character', 'If']\n",
      "['If', 'You']\n",
      "['You', 'Are']\n",
      "['Are', 'Working']\n",
      "['Working', 'On']\n",
      "['On', 'Something']\n",
      "['Something', 'That']\n",
      "['That', 'You']\n",
      "['You', 'Really']\n",
      "['Really', 'Care']\n",
      "['Care', 'About']\n",
      "['About', 'You']\n",
      "['You', 'Don']\n",
      "['Don', '’']\n",
      "['’', 't']\n",
      "['t', 'Have']\n",
      "['Have', 'To']\n",
      "['To', 'Be']\n",
      "['Be', 'Pushed']\n",
      "['Pushed', 'The']\n",
      "['The', 'Vision']\n",
      "['Vision', 'Pulls']\n",
      "['Pulls', 'You']\n",
      "['You', 'The']\n",
      "['The', 'purpose']\n",
      "['purpose', 'of']\n",
      "['of', 'software']\n",
      "['software', 'engineering']\n",
      "['engineering', 'is']\n",
      "['is', 'to']\n",
      "['to', 'control']\n",
      "['control', 'complexity']\n",
      "['complexity', 'not']\n",
      "['not', 'to']\n",
      "['to', 'create']\n",
      "['create', 'it']\n"
     ]
    }
   ],
   "source": [
    "# Bi-Gram\n",
    "for bigram in blob.ngrams(2):\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'best', 'error']\n",
      "['best', 'error', 'message']\n",
      "['error', 'message', 'is']\n",
      "['message', 'is', 'the']\n",
      "['is', 'the', 'one']\n",
      "['the', 'one', 'that']\n",
      "['one', 'that', 'never']\n",
      "['that', 'never', 'shows']\n",
      "['never', 'shows', 'up']\n",
      "['shows', 'up', 'You']\n",
      "['up', 'You', 'Learn']\n",
      "['You', 'Learn', 'More']\n",
      "['Learn', 'More', 'From']\n",
      "['More', 'From', 'Failure']\n",
      "['From', 'Failure', 'Than']\n",
      "['Failure', 'Than', 'From']\n",
      "['Than', 'From', 'Success']\n",
      "['From', 'Success', 'Don']\n",
      "['Success', 'Don', '’']\n",
      "['Don', '’', 't']\n",
      "['’', 't', 'Let']\n",
      "['t', 'Let', 'It']\n",
      "['Let', 'It', 'Stop']\n",
      "['It', 'Stop', 'You']\n",
      "['Stop', 'You', 'Failure']\n",
      "['You', 'Failure', 'Builds']\n",
      "['Failure', 'Builds', 'Character']\n",
      "['Builds', 'Character', 'If']\n",
      "['Character', 'If', 'You']\n",
      "['If', 'You', 'Are']\n",
      "['You', 'Are', 'Working']\n",
      "['Are', 'Working', 'On']\n",
      "['Working', 'On', 'Something']\n",
      "['On', 'Something', 'That']\n",
      "['Something', 'That', 'You']\n",
      "['That', 'You', 'Really']\n",
      "['You', 'Really', 'Care']\n",
      "['Really', 'Care', 'About']\n",
      "['Care', 'About', 'You']\n",
      "['About', 'You', 'Don']\n",
      "['You', 'Don', '’']\n",
      "['Don', '’', 't']\n",
      "['’', 't', 'Have']\n",
      "['t', 'Have', 'To']\n",
      "['Have', 'To', 'Be']\n",
      "['To', 'Be', 'Pushed']\n",
      "['Be', 'Pushed', 'The']\n",
      "['Pushed', 'The', 'Vision']\n",
      "['The', 'Vision', 'Pulls']\n",
      "['Vision', 'Pulls', 'You']\n",
      "['Pulls', 'You', 'The']\n",
      "['You', 'The', 'purpose']\n",
      "['The', 'purpose', 'of']\n",
      "['purpose', 'of', 'software']\n",
      "['of', 'software', 'engineering']\n",
      "['software', 'engineering', 'is']\n",
      "['engineering', 'is', 'to']\n",
      "['is', 'to', 'control']\n",
      "['to', 'control', 'complexity']\n",
      "['control', 'complexity', 'not']\n",
      "['complexity', 'not', 'to']\n",
      "['not', 'to', 'create']\n",
      "['to', 'create', 'it']\n"
     ]
    }
   ],
   "source": [
    "# Tri-Gram\n",
    "for trigram in blob.ngrams(3):\n",
    "    print(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important features of textblob\n",
    "\n",
    "#Detect_language()\n",
    "#Translate(to='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "myword = TextBlob(\"Hello, I am one of the scientists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myword.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "myword2 = TextBlob(\"வணக்கம், நான் விஞ்ஞானிகளில் ஒருவன்\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ta'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myword2.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"வணக்கம், நான் விஞ்ஞானிகளில் ஒருவன்\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Translation to French\n",
    "myword.translate(to='ta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob1 = TextBlob(\"Hello world this is NLP with TextBlob for text classification.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 'NNP'),\n",
       " ('world', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('NLP', 'NNP'),\n",
       " ('with', 'IN'),\n",
       " ('TextBlob', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('text', 'JJ'),\n",
       " ('classification', 'NN')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob1.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Venkatesan R\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 'NNP'),\n",
       " ('world', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('NLP', 'NNP'),\n",
       " ('with', 'IN'),\n",
       " ('TextBlob', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('text', 'JJ'),\n",
       " ('classification', 'NN')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob1.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytree = [\"study\",\"studying\",\"student\",\"studies\",\"studious\"]\n",
    "myblog = [\"blog\",\"blogging\",\"logging\",\"blogger\",\"logs\",\"vlogs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob,Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Venkatesan\n",
      "[nltk_data]     R\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = Word('running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.lemmatize('v') #verb lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2 = Word('finding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'find'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex2.lemmatize('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study', 'studying', 'student', 'studies', 'studious']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study => study\n",
      "studying => studying\n",
      "student => student\n",
      "studies => study\n",
      "studious => studious\n"
     ]
    }
   ],
   "source": [
    "# Lemmatizing a list of words based on noun\n",
    "for i in mytree:\n",
    "    result = Word(i).lemmatize('n')\n",
    "    print(f'{i} => {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfeelings = [\"I love my phone but would not recommend it to any of my colleagues\",\n",
    "              \"I love this watch\",\n",
    "              \"This is an amazing library\",\n",
    "              \"I do not like this restaurant\",\n",
    "              \"Wow what a great tip.\",\n",
    "             \"a surprisingly interesting movie\",\n",
    "              \"hard to resist\",\n",
    "              \"one lousy film\",\n",
    "              \"this is too long\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love my phone but would not recommend it to any of my colleagues ==> polarity:  0.5\n",
      "I love this watch ==> polarity:  0.5\n",
      "This is an amazing library ==> polarity:  0.6000000000000001\n",
      "I do not like this restaurant ==> polarity:  0.0\n",
      "Wow what a great tip. ==> polarity:  0.45\n",
      "a surprisingly interesting movie ==> polarity:  0.5\n",
      "hard to resist ==> polarity:  -0.2916666666666667\n",
      "one lousy film ==> polarity:  -0.5\n",
      "this is too long ==> polarity:  -0.05\n"
     ]
    }
   ],
   "source": [
    "for f in myfeelings:\n",
    "    result = TextBlob(f).sentiment.polarity\n",
    "    print(f'{f} ==> polarity:  {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
